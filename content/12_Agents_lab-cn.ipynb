{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ef3adc8",
   "metadata": {},
   "source": [
    "# ç®€å•çš„è¯­ä¹‰å†…æ ¸ä»£ç†æ•™ç¨‹\n",
    "\n",
    "åªéœ€å‡ ä¸ªæ­¥éª¤ï¼Œå³å¯å­¦ä¹ ä½¿ç”¨è¯­ä¹‰å†…æ ¸æ„å»º AI ä»£ç†ã€‚æœ¬æ•™ç¨‹æ¶µç›–äº†åŸºæœ¬è¦ç´ ï¼šåˆ›å»ºä»£ç†ã€æ·»åŠ å·¥å…·å’Œç®¡ç†å¯¹è¯ã€‚\n",
    "\n",
    "è¯­ä¹‰å†…æ ¸ä»£ç†ä¸­æœ‰ä¸‰ä¸ªåŸºæœ¬ç»„ä»¶ï¼š\n",
    "1. ä»£ç†ç±»ï¼šæ‰€æœ‰ä»£ç†ç±»å‹éƒ½ç»§æ‰¿è‡ªæ­¤ç±»ã€‚ä»£ç†ç±»å‹åŒ…æ‹¬ ChatCompletionAgentï¼ˆä½¿ç”¨æ ‡å‡†èŠå¤©å®Œæˆ APIï¼‰ã€OpenAIAssistantAgentï¼ˆåˆ©ç”¨ OpenAI Assistant API å’Œå†…ç½®å·¥å…·ï¼‰ã€AzureAIAgentï¼ˆä¸ Azure AI æœåŠ¡é›†æˆä»¥ç”¨äºä¼ä¸šåœºæ™¯ï¼‰ã€CopilotStudioAgentï¼ˆè¿æ¥åˆ° Microsoft Copilot Studio å·¥ä½œæµï¼‰ã€‚\n",
    "2. ä»£ç†çº¿ç¨‹ï¼šè¿™å¤„ç†å¯¹è¯å†å²å’ŒçŠ¶æ€çš„ç»´æŠ¤æ–¹å¼ã€‚è¿™å¾ˆé‡è¦ï¼Œå› ä¸ºä»£ç†éœ€è¦æ¥è‡ªå…ˆå‰æ¶ˆæ¯çš„ä¸Šä¸‹æ–‡æ¥åšå‡ºæ˜æ™ºçš„å†³å®šã€‚æœ‰ä¸¤ç§æ–¹æ³•ï¼š\n",
    "    1. æœåŠ¡ç®¡ç†çŠ¶æ€ï¼šåƒ Azure AI è¿™æ ·çš„ä»£ç†æœåŠ¡å°†å¯¹è¯å†å²å­˜å‚¨åœ¨æœåŠ¡å™¨ç«¯ï¼Œå¹¶é€šè¿‡çº¿ç¨‹ ID è®¿é—®ã€‚\n",
    "    2. åº”ç”¨ç¨‹åºç®¡ç†çŠ¶æ€ï¼šæ‚¨çš„åº”ç”¨ç¨‹åºç»´æŠ¤å®Œæ•´çš„èŠå¤©å†å²ï¼Œå¹¶åœ¨æ¯æ¬¡è°ƒç”¨æ—¶å°†å…¶ä¼ é€’ç»™ä»£ç†ã€‚\n",
    "3. ä»£ç†ç¼–æ’ï¼šè¯¥æ¡†æ¶æä¾›äº†é¢„æ„å»ºçš„æ¨¡å¼ï¼Œç”¨äºåè°ƒå¤šä¸ªä»£ç†ä»¥å¤„ç†å•ä¸ªä»£ç†æ— æ³•æœ‰æ•ˆç®¡ç†çš„å¤æ‚å·¥ä½œæµã€‚\n",
    "    1. é¡ºåºï¼šä»£ç†æŒ‰é¡ºåºä¸€ä¸ªæ¥ä¸€ä¸ªåœ°æ‰§è¡Œã€‚è¿™å°±åƒæ–‡æ¡£å¤„ç†ç®¡é“ã€‚\n",
    "    2. å¹¶å‘ï¼šå¤šä¸ªä»£ç†åŒæ—¶å·¥ä½œã€‚å°±åƒå®¢æˆ·æŸ¥è¯¢å¤„ç†ï¼ˆè®¡è´¹ä»£ç†å’Œå®¢æˆ·ä»£ç†å¹¶è¡Œå·¥ä½œï¼‰ã€‚\n",
    "    3. ç§»äº¤ï¼šä»£ç†æ ¹æ®ä¸“ä¸šåŒ–ç›¸äº’ä¼ é€’æ§åˆ¶æƒã€‚å°±åƒå®¢æˆ·æœåŠ¡åˆ†æµç»™ä¸“å®¶ä»£ç†ã€‚\n",
    "    4. ç¾¤èŠï¼šä»£ç†åœ¨å…±äº«å¯¹è¯ä¸­åä½œã€‚å°±åƒä¸é¢†åŸŸä¸“å®¶è¿›è¡Œé¡¹ç›®è§„åˆ’ã€‚\n",
    "\n",
    "ä»£ç†åˆ©ç”¨è¯­ä¹‰å†…æ ¸çš„æ’ä»¶ç³»ç»Ÿæ¥è®¿é—®å·¥å…·ã€æ•°æ®åº“ç­‰ã€‚\n",
    "\n",
    "ä»£ç†ä¹Ÿå¯ä»¥ä½¿ç”¨ YAML å®šä¹‰ã€‚\n",
    "\n",
    "## è®¾ç½®\n",
    "\n",
    "å®‰è£…æ‰€éœ€çš„åŒ…å¹¶é…ç½®æ‚¨çš„ç¯å¢ƒï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee165f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages\n",
    "!pip install semantic-kernel python-dotenv\n",
    "\n",
    "# Import everything we need\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.agents import ChatCompletionAgent\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
    "from semantic_kernel.functions import kernel_function\n",
    "\n",
    "print(\"âœ… Setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8a33b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Check if API key is configured\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not OPENAI_API_KEY:\n",
    "    print(\"âš ï¸  Please add OPENAI_API_KEY to your .env file!\")\n",
    "    print(\"   Create a .env file with: OPENAI_API_KEY=your_actual_key_here\")\n",
    "else:\n",
    "    print(\"âœ… API key configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4562fa7c",
   "metadata": {},
   "source": [
    "## æ­¥éª¤ 1ï¼šåˆ›å»ºä¸€ä¸ªç®€å•çš„ä»£ç†\n",
    "\n",
    "è®©æˆ‘ä»¬ä»åŸºç¡€å¼€å§‹â€”â€”ä¸€ä¸ªå¯ä»¥èŠå¤©çš„ä»£ç†ã€‚æˆ‘ä»¬åªæ˜¯è®©å†…æ ¸ï¼ˆæˆ‘ä»¬çš„åè°ƒå™¨ï¼‰è®¿é—®èŠå¤©æœåŠ¡ï¼Œè¯¥æœåŠ¡åˆ©ç”¨äº† OpenAI çš„èŠå¤©å®Œæˆ API ç«¯ç‚¹ã€‚æˆ‘ä»¬ç¨åä¼šæ·»åŠ æ›´å¤šå·¥å…·ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7719da92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create service and kernel\n",
    "chat_service = OpenAIChatCompletion(\n",
    "    ai_model_id=\"gpt-4o-mini\",\n",
    "    api_key=OPENAI_API_KEY\n",
    ")\n",
    "\n",
    "kernel = Kernel()\n",
    "kernel.add_service(chat_service)\n",
    "\n",
    "# Create a basic agent\n",
    "agent = ChatCompletionAgent(\n",
    "    kernel=kernel,\n",
    "    name=\"Assistant\",\n",
    "    instructions=\"You are a helpful and friendly assistant.\"\n",
    ")\n",
    "\n",
    "# Test it\n",
    "response = await agent.get_response(\"Hello! What can you help me with?\")\n",
    "print(f\"ğŸ¤– {agent.name}: {response.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c6a9cb",
   "metadata": {},
   "source": [
    "## æ­¥éª¤ 2ï¼šæ·»åŠ å·¥å…·ï¼ˆå‡½æ•°ï¼‰\n",
    "\n",
    "ç°åœ¨è®©æˆ‘ä»¬ç»™æˆ‘ä»¬çš„ä»£ç†ä¸€äº›æœ‰ç”¨çš„åŠŸèƒ½ã€‚æˆ‘ä»¬å°†ç»™å®ƒä¸€ä¸ªå¤©æ°”å‡½æ•°å’Œä¸€ä¸ªè®¡ç®—å™¨ã€‚è¿™ä¸¤ä¸ªéƒ½æ˜¯æˆ‘ä»¬åœ¨ä»£ç ä¸­å®šä¹‰çš„å‡½æ•°ï¼Œå¹¶å°†å®ƒä»¬ä½œä¸ºå·¥å…·æä¾›ç»™å†…æ ¸ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1738b051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define useful functions\n",
    "@kernel_function(description=\"Get current weather for a city\")\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Mock weather function - replace with real API call.\"\"\"\n",
    "    weather_data = {\n",
    "        \"london\": \"Cloudy, 15Â°C\",\n",
    "        \"paris\": \"Sunny, 22Â°C\", \n",
    "        \"tokyo\": \"Rainy, 18Â°C\",\n",
    "        \"new york\": \"Partly cloudy, 20Â°C\"\n",
    "    }\n",
    "    return weather_data.get(city.lower(), f\"Weather data not available for {city}\")\n",
    "\n",
    "@kernel_function(description=\"Calculate simple math expressions\")\n",
    "def calculate(expression: str) -> str:\n",
    "    \"\"\"Safe calculator for basic math.\"\"\"\n",
    "    try:\n",
    "        # Only allow basic math operations for safety\n",
    "        allowed_chars = \"0123456789+-*/(). \"\n",
    "        if all(c in allowed_chars for c in expression):\n",
    "            result = eval(expression)\n",
    "            return f\"{expression} = {result}\"\n",
    "        else:\n",
    "            return \"Sorry, I can only do basic math operations (+, -, *, /, parentheses)\"\n",
    "    except:\n",
    "        return \"Sorry, I couldn't calculate that. Please check your expression.\"\n",
    "\n",
    "# Add functions to kernel\n",
    "kernel.add_function(plugin_name=\"tools\", function=get_weather)\n",
    "kernel.add_function(plugin_name=\"tools\", function=calculate)\n",
    "\n",
    "# Create enhanced agent\n",
    "enhanced_agent = ChatCompletionAgent(\n",
    "    kernel=kernel,\n",
    "    name=\"SmartAssistant\",\n",
    "    instructions=\"\"\"\n",
    "    You are a helpful assistant with weather and calculator capabilities.\n",
    "    \n",
    "    - Use get_weather when asked about weather in specific cities\n",
    "    - Use calculate for math problems\n",
    "    - Be friendly and explain what you're doing\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "print(\"âœ… Enhanced agent created with tools!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef5f43d",
   "metadata": {},
   "source": [
    "## æ­¥éª¤ 3ï¼šä½¿ç”¨å·¥å…·æµ‹è¯•ä»£ç†\n",
    "\n",
    "è®©æˆ‘ä»¬çœ‹çœ‹æˆ‘ä»¬çš„ä»£ç†å¦‚ä½•ä½¿ç”¨å®ƒçš„å·¥å…·ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b08a293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test weather function\n",
    "print(\"ğŸŒ¤ï¸ Testing weather function:\")\n",
    "response = await enhanced_agent.get_response(\"What's the weather in London?\")\n",
    "print(f\"ğŸ¤– {enhanced_agent.name}: {response.content}\\n\")\n",
    "\n",
    "# Test calculator function  \n",
    "print(\"ğŸ§® Testing calculator function:\")\n",
    "response = await enhanced_agent.get_response(\"What's 25 * 4 + 10?\")\n",
    "print(f\"ğŸ¤– {enhanced_agent.name}: {response.content}\\n\")\n",
    "\n",
    "# Test general conversation\n",
    "print(\"ğŸ’¬ Testing general conversation:\")\n",
    "response = await enhanced_agent.get_response(\"Tell me a fun fact about AI\")\n",
    "print(f\"ğŸ¤– {enhanced_agent.name}: {response.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3d4c18",
   "metadata": {},
   "source": [
    "## æ­¥éª¤ 4ï¼šå¸¦è®°å¿†çš„å¯¹è¯\n",
    "\n",
    "å¯¹äºèƒ½å¤Ÿè®°ä½å…ˆå‰æ¶ˆæ¯çš„å¯¹è¯ã€‚æˆ‘ä»¬å°†ä½¿ç”¨è¯­ä¹‰å†…æ ¸å¼€ç®±å³ç”¨çš„å†…å­˜ç®¡ç†ï¼Œä½†è¿™å°†å–å†³äºä¸Šä¸‹æ–‡çª—å£ã€‚\n",
    "\n",
    "å†…å­˜é—®é¢˜å¯ä»¥é€šè¿‡æ€»ç»“è¿‡å»çš„å¯¹è¯æˆ–ä½¿ç”¨åƒ RAG è¿™æ ·çš„é•¿æœŸè®°å¿†æ¥è§£å†³ã€‚è¿˜æœ‰ä¸€ç§å­¦ä¹ è®°å¿†ï¼Œæˆ‘ä»¬å¸Œæœ›ä»£ç†ä»æ‰€æœ‰è¿‡å»çš„äº¤äº’ä¸­å­¦ä¹ ï¼Œè¿™ä¹Ÿæ˜¯é€šè¿‡ RAG å®ç°çš„ï¼Œæˆ‘ä»¬å­˜å‚¨æˆåŠŸçš„è§£å†³æ–¹æ¡ˆç¤ºä¾‹ï¼Œå¹¶åœ¨ç±»ä¼¼æƒ…å†µä¸‹æ£€ç´¢å®ƒä»¬ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34cc3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def chat_with_memory():\n",
    "    \"\"\"Demonstrate conversation with memory.\"\"\"\n",
    "    \n",
    "    print(\"ğŸ’­ Conversation with Memory Demo\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Messages that build on each other\n",
    "    messages = [\n",
    "        \"Hi! I'm planning a trip to Paris.\",\n",
    "        \"What's the weather like there?\",\n",
    "        \"That sounds nice! Can you calculate 150 * 7 for my budget?\",\n",
    "        \"Perfect, that should cover my week there. Thanks!\"\n",
    "    ]\n",
    "    \n",
    "    thread = None  # This will store conversation history\n",
    "    \n",
    "    for msg in messages:\n",
    "        print(f\"ğŸ‘¤ User: {msg}\")\n",
    "        \n",
    "        # Agent remembers previous messages through the thread\n",
    "        response = await enhanced_agent.get_response(messages=msg, thread=thread)\n",
    "        print(f\"ğŸ¤– {enhanced_agent.name}: {response.content}\\n\")\n",
    "        \n",
    "        # Update thread to keep conversation history\n",
    "        thread = response.thread\n",
    "\n",
    "# Run the conversation demo\n",
    "await chat_with_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfadd9df",
   "metadata": {},
   "source": [
    "## æ­¥éª¤ 5ï¼šæŸ¥çœ‹å·¥å…·çš„å®é™…æ“ä½œï¼ˆé«˜çº§ï¼‰\n",
    "\n",
    "ç¡®åˆ‡åœ°è§‚å¯Ÿå½“æ‚¨çš„ä»£ç†ä½¿ç”¨å·¥å…·æ—¶ä¼šå‘ç”Ÿä»€ä¹ˆï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71d9b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def show_tool_usage():\n",
    "    \"\"\"Show detailed tool execution.\"\"\"\n",
    "    \n",
    "    print(\"ğŸ”§ Tool Usage Demo\")\n",
    "    print(\"=\" * 25)\n",
    "    \n",
    "    # Callback to see tool calls\n",
    "    async def log_tool_calls(message):\n",
    "        from semantic_kernel.contents import FunctionCallContent, FunctionResultContent\n",
    "        \n",
    "        for item in message.items or []:\n",
    "            if isinstance(item, FunctionCallContent):\n",
    "                print(f\"  ğŸ”§ Calling: {item.name}({item.arguments})\")\n",
    "            elif isinstance(item, FunctionResultContent):\n",
    "                print(f\"  âœ… Result: {item.result}\")\n",
    "    \n",
    "    user_input = \"What's the weather in Tokyo and what's 15 + 27?\"\n",
    "    print(f\"ğŸ‘¤ User: {user_input}\\n\")\n",
    "    \n",
    "    # Use invoke to see intermediate steps\n",
    "    async for response in enhanced_agent.invoke(\n",
    "        messages=user_input,\n",
    "        on_intermediate_message=log_tool_calls\n",
    "    ):\n",
    "        print(f\"\\nğŸ¤– Final Response: {response.content}\")\n",
    "\n",
    "# Run the tool usage demo\n",
    "await show_tool_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccb8929",
   "metadata": {},
   "source": [
    "## æ­¥éª¤ 6ï¼šæµå¼å“åº”\n",
    "\n",
    "å¯¹äºå®æ—¶å“åº”ï¼ˆå¦‚ ChatGPTï¼‰ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89f1dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def streaming_demo():\n",
    "    \"\"\"Show streaming responses.\"\"\"\n",
    "    \n",
    "    print(\"\\nğŸŒŠ Streaming Demo\")\n",
    "    print(\"=\" * 20)\n",
    "    \n",
    "    print(\"ğŸ‘¤ User: Write a short poem about coding\")\n",
    "    print(\"ğŸ¤– Assistant: \", end=\"\", flush=True)\n",
    "    \n",
    "    # Stream response word by word\n",
    "    async for chunk in enhanced_agent.invoke_stream(\n",
    "        messages=\"Write a short poem about coding\"\n",
    "    ):\n",
    "        print(chunk.content, end=\"\", flush=True)\n",
    "    \n",
    "    print(\"\\n\")  # New line when done\n",
    "\n",
    "# Run streaming demo\n",
    "await streaming_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7cf05d",
   "metadata": {},
   "source": [
    "\n",
    "## æ€»ç»“ï¼šæ‚¨å­¦åˆ°äº†ä»€ä¹ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb0b494",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ“ What You've Built:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "summary = [\n",
    "    \"âœ… Basic AI agent with OpenAI\",\n",
    "    \"âœ… Custom tools/functions for weather and math\", \n",
    "    \"âœ… Conversation memory management\",\n",
    "    \"âœ… Tool execution monitoring\",\n",
    "    \"âœ… Real-time streaming responses\"\n",
    "]\n",
    "\n",
    "for item in summary:\n",
    "    print(item)\n",
    "\n",
    "print(\"\\nğŸš€ Key Concepts:\")\n",
    "concepts = {\n",
    "    \"Agent\": \"AI that can reason, remember, and use tools\",\n",
    "    \"Kernel\": \"Manages AI services and functions\",\n",
    "    \"Functions\": \"Tools that extend agent capabilities\", \n",
    "    \"Thread\": \"Maintains conversation history\",\n",
    "    \"Streaming\": \"Real-time response generation\"\n",
    "}\n",
    "\n",
    "for concept, description in concepts.items():\n",
    "    print(f\"â€¢ {concept}: {description}\")\n",
    "\n",
    "print(\"\\nğŸ’¡ Next Steps:\")\n",
    "print(\"â€¢ Try different models (gpt-4, gpt-3.5-turbo)\")\n",
    "print(\"â€¢ Create custom functions for your use case\")\n",
    "print(\"â€¢ Explore multi-agent conversations\")\n",
    "print(\"â€¢ Add guardrails for production safety\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdc124f",
   "metadata": {},
   "source": [
    "## æ­¥éª¤ 7ï¼šé¡ºåºä»£ç†ç¼–æ’\n",
    "\n",
    "ç°åœ¨è®©æˆ‘ä»¬çœ‹çœ‹å¤šä¸ªä»£ç†å¦‚ä½•åœ¨ä¸€ä¸ªç®¡é“ä¸­ååŒå·¥ä½œâ€”â€”æ¯ä¸ªä»£ç†å¤„ç†å‰ä¸€ä¸ªä»£ç†çš„è¾“å‡ºã€‚è¯·æ³¨æ„è¯­ä¹‰å†…æ ¸ä¸ºæˆ‘ä»¬å®ç°è¿™ä¸€ç‚¹æ˜¯å¤šä¹ˆå®¹æ˜“ï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e03de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import orchestration components\n",
    "from semantic_kernel.agents import SequentialOrchestration\n",
    "from semantic_kernel.agents.runtime import InProcessRuntime\n",
    "from semantic_kernel.contents import ChatMessageContent\n",
    "\n",
    "print(\"ğŸ”— Setting up Sequential Agent Pipeline\")\n",
    "print(\"=\" * 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea6ec99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create specialized agents for a marketing pipeline\n",
    "def create_marketing_pipeline():\n",
    "    \"\"\"Create three agents that work together sequentially.\"\"\"\n",
    "    \n",
    "    # Agent 1: Extract key information\n",
    "    concept_extractor = ChatCompletionAgent(\n",
    "        name=\"ConceptExtractor\",\n",
    "        instructions=\"\"\"\n",
    "        You are a marketing analyst. Given a product description, identify:\n",
    "        - Key features (bullet points)\n",
    "        - Target audience \n",
    "        - Unique selling points\n",
    "        \n",
    "        Format your output clearly with headers.\n",
    "        \"\"\",\n",
    "        kernel=kernel\n",
    "    )\n",
    "    \n",
    "    # Agent 2: Write marketing copy\n",
    "    copywriter = ChatCompletionAgent(\n",
    "        name=\"Copywriter\", \n",
    "        instructions=\"\"\"\n",
    "        You are a marketing copywriter. Take the analysis provided and write \n",
    "        compelling marketing copy (around 100-150 words). Make it engaging \n",
    "        and highlight the key benefits. Output just the marketing copy.\n",
    "        \"\"\",\n",
    "        kernel=kernel\n",
    "    )\n",
    "    \n",
    "    # Agent 3: Polish and format\n",
    "    editor = ChatCompletionAgent(\n",
    "        name=\"Editor\",\n",
    "        instructions=\"\"\"\n",
    "        You are an editor. Take the marketing copy and polish it:\n",
    "        - Fix grammar and clarity\n",
    "        - Ensure consistent tone\n",
    "        - Make it more compelling\n",
    "        - Output the final polished version\n",
    "        \"\"\",\n",
    "        kernel=kernel\n",
    "    )\n",
    "    \n",
    "    return [concept_extractor, copywriter, editor]\n",
    "\n",
    "# Create the pipeline\n",
    "marketing_agents = create_marketing_pipeline()\n",
    "print(f\"âœ… Created {len(marketing_agents)} specialized agents:\")\n",
    "for agent in marketing_agents:\n",
    "    print(f\"   â€¢ {agent.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07895a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up callback to see each agent's work\n",
    "def agent_callback(message: ChatMessageContent) -> None:\n",
    "    \"\"\"Show what each agent produces.\"\"\"\n",
    "    print(f\"\\nğŸ¤– {message.name}:\")\n",
    "    print(\"-\" * 30)\n",
    "    print(message.content)\n",
    "    print()\n",
    "\n",
    "# Create the sequential orchestration\n",
    "sequential_pipeline = SequentialOrchestration(\n",
    "    members=marketing_agents,\n",
    "    agent_response_callback=agent_callback\n",
    ")\n",
    "\n",
    "print(\"ğŸ”— Sequential pipeline created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dbd8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the sequential pipeline\n",
    "async def run_marketing_pipeline():\n",
    "    \"\"\"Execute the sequential agent pipeline.\"\"\"\n",
    "    \n",
    "    print(\"ğŸš€ Running Marketing Pipeline\")\n",
    "    print(\"=\" * 35)\n",
    "    \n",
    "    # Start the runtime\n",
    "    runtime = InProcessRuntime()\n",
    "    runtime.start()\n",
    "    \n",
    "    try:\n",
    "        # Input: Product description\n",
    "        product_description = (\n",
    "            \"A smart water bottle with temperature display, \"\n",
    "            \"app connectivity, hydration reminders, and \"\n",
    "            \"leak-proof design. Made from BPA-free materials.\"\n",
    "        )\n",
    "        \n",
    "        print(f\"ğŸ“ Input Product: {product_description}\\n\")\n",
    "        print(\"Processing through pipeline...\")\n",
    "        \n",
    "        # Run the sequential orchestration\n",
    "        result = await sequential_pipeline.invoke(\n",
    "            task=product_description,\n",
    "            runtime=runtime\n",
    "        )\n",
    "        \n",
    "        # Get final result\n",
    "        final_output = await result.get(timeout=30)\n",
    "        \n",
    "        print(\"ğŸ¯ FINAL MARKETING COPY:\")\n",
    "        print(\"=\" * 40)\n",
    "        print(final_output)\n",
    "        \n",
    "    finally:\n",
    "        # Clean up\n",
    "        await runtime.stop_when_idle()\n",
    "\n",
    "# Execute the pipeline\n",
    "await run_marketing_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6452fa4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick demo with a different product\n",
    "async def quick_pipeline_demo():\n",
    "    \"\"\"Quick demo with another product.\"\"\"\n",
    "    \n",
    "    print(\"\\nğŸ”„ Quick Pipeline Demo #2\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    runtime = InProcessRuntime()\n",
    "    runtime.start()\n",
    "    \n",
    "    try:\n",
    "        # Different product\n",
    "        product = \"Wireless earbuds with 30-hour battery, noise cancellation, and workout-proof design\"\n",
    "        \n",
    "        print(f\"ğŸ“ Product: {product}\")\n",
    "        \n",
    "        # Simple pipeline without detailed logging\n",
    "        simple_pipeline = SequentialOrchestration(members=marketing_agents)\n",
    "        \n",
    "        result = await simple_pipeline.invoke(\n",
    "            task=product,\n",
    "            runtime=runtime\n",
    "        )\n",
    "        \n",
    "        final_copy = await result.get(timeout=30)\n",
    "        print(f\"\\nğŸ¯ Final Copy:\\n{final_copy}\")\n",
    "        \n",
    "    finally:\n",
    "        await runtime.stop_when_idle()\n",
    "\n",
    "# Run quick demo\n",
    "await quick_pipeline_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff49f96",
   "metadata": {},
   "source": [
    "\n",
    "## æ€»ç»“ï¼šæ‚¨å­¦åˆ°äº†ä»€ä¹ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f920877",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ“ Complete Tutorial Summary:\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "summary = [\n",
    "    \"âœ… Basic AI agent with OpenAI\",\n",
    "    \"âœ… Custom tools/functions for weather and math\", \n",
    "    \"âœ… Conversation memory management\",\n",
    "    \"âœ… Tool execution monitoring\",\n",
    "    \"âœ… Real-time streaming responses\",\n",
    "    \"âœ… Sequential agent orchestration\"\n",
    "]\n",
    "\n",
    "for item in summary:\n",
    "    print(item)\n",
    "\n",
    "print(\"\\nğŸš€ Key Concepts:\")\n",
    "concepts = {\n",
    "    \"Agent\": \"AI that can reason, remember, and use tools\",\n",
    "    \"Kernel\": \"Manages AI services and functions\",\n",
    "    \"Functions\": \"Tools that extend agent capabilities\", \n",
    "    \"Thread\": \"Maintains conversation history\",\n",
    "    \"Streaming\": \"Real-time response generation\",\n",
    "    \"Sequential Orchestration\": \"Pipeline where agents process output sequentially\"\n",
    "}\n",
    "\n",
    "for concept, description in concepts.items():\n",
    "    print(f\"â€¢ {concept}: {description}\")\n",
    "\n",
    "print(\"\\nğŸ’¡ Agent Patterns:\")\n",
    "patterns = [\n",
    "    \"Single Agent: One agent handles entire workflow\",\n",
    "    \"Sequential: Agents work in pipeline (A â†’ B â†’ C)\",\n",
    "    \"Concurrent: Multiple agents work simultaneously\", \n",
    "    \"Manager: Central agent coordinates specialists\",\n",
    "    \"Handoff: Agents pass control to each other\"\n",
    "]\n",
    "\n",
    "for pattern in patterns:\n",
    "    print(f\"â€¢ {pattern}\")\n",
    "\n",
    "print(\"\\nğŸ¯ When to Use Sequential Orchestration:\")\n",
    "use_cases = [\n",
    "    \"â€¢ Document processing (extract â†’ summarize â†’ format)\",\n",
    "    \"â€¢ Content creation (research â†’ write â†’ edit)\", \n",
    "    \"â€¢ Data analysis (collect â†’ analyze â†’ visualize)\",\n",
    "    \"â€¢ Code review (analyze â†’ suggest â†’ validate)\"\n",
    "]\n",
    "\n",
    "for use_case in use_cases:\n",
    "    print(use_case)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dde95b3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**ğŸ”‘ å…³é”®è¦ç‚¹ï¼š**\n",
    "- **å•ä¸€ä»£ç†**ï¼šéå¸¸é€‚åˆç®€å•çš„ä»»åŠ¡å’Œå­¦ä¹ \n",
    "- **é¡ºåºç¼–æ’**ï¼šéå¸¸é€‚åˆå¤šæ­¥éª¤å·¥ä½œæµï¼Œå…¶ä¸­æ¯ä¸ªæ­¥éª¤éƒ½å»ºç«‹åœ¨å‰ä¸€ä¸ªæ­¥éª¤çš„åŸºç¡€ä¸Š\n",
    "- **ä¸“ä¸šåŒ–**ï¼šæ¯ä¸ªä»£ç†éƒ½ä¸“æ³¨äºè‡ªå·±æœ€æ“…é•¿çš„äº‹æƒ…\n",
    "- **ç®¡é“ä¼˜åŠ¿**ï¼šé€šè¿‡ä¸“ä¸šåŒ–å¤„ç†è·å¾—æ›´å¥½çš„è´¨é‡\n",
    "- **å®é™…åº”ç”¨**ï¼šæ–‡æ¡£å¤„ç†ã€å†…å®¹åˆ›å»ºã€æ•°æ®åˆ†æ\n",
    "\n",
    "æœ¬æ•™ç¨‹æ¶µç›–äº†ä»åŸºæœ¬ä»£ç†åˆ°å¤æ‚çš„å¤šä»£ç†ç®¡é“çš„æ‰€æœ‰å†…å®¹ï¼"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
