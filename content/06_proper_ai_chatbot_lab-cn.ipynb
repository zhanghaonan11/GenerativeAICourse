{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0845b300",
   "metadata": {},
   "source": [
    "\n",
    "# 使用Gradio构建交互式AI应用程序\n",
    "\n",
    "本实验指导您使用Gradio创建交互式AI应用程序，重点是构建具有流式响应的可定制聊天机器人。\n",
    "\n",
    "Gradio是一个Python前端库，使构建聊天机器人体验变得非常容易。\n",
    "\n",
    "## 先决条件\n",
    "\n",
    "开始之前，请确保您拥有必要的包："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c5b375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install gradio openai python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70aafced",
   "metadata": {},
   "source": [
    "## 1. 设置您的环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a406ce56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gradio as gr\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables (if using .env file)\n",
    "load_dotenv()\n",
    "\n",
    "# IMPORTANT: Set your API key directly (for testing only)\n",
    "# NOTE: For security reasons, you should use a .env file instead in production\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "# Now initialize the OpenAI client\n",
    "\n",
    "# Verify API key\n",
    "if os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    print(\"OpenAI API Key loaded successfully\")\n",
    "else:\n",
    "    print(\"ERROR: OpenAI API Key not found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ceecbf",
   "metadata": {},
   "source": [
    "## 2. 您的第一个Gradio界面\n",
    "\n",
    "让我们创建一个简单的Gradio界面："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb4d305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will define a simple function called echo, all it does is it will accept a message \n",
    "# and simply return it back!\n",
    "def echo(message):\n",
    "    return f\"You said: {message}\"\n",
    "\n",
    "# Create a basic Gradio interface. gr.interface() is a function that creates a web-based UI \n",
    "# for your function, basically what that means is that it will create a web page where you \n",
    "# can enter text and see the output. That interface will be hosted on a local server, and \n",
    "# you can access it via your web browser.\n",
    "# The interface accepts the function to be called (echo in this case), the input type \n",
    "# (textbox), and the output type (also textbox). The title and description are optional, \n",
    "# but they help to provide context for the user. Flagging mode is set to \"never\" to \n",
    "# disable the flagging feature to make it look better.\n",
    "# When you run this function, it will spin up an interface with input and output boxes, \n",
    "# and a button to submit the input. When you submit the input, it will call the echo \n",
    "# function with the input text and display the output in the output box.\n",
    "demo = gr.Interface(\n",
    "    fn=echo,\n",
    "    inputs=\"textbox\",\n",
    "    outputs=\"textbox\",\n",
    "    title=\"Echo Bot\",\n",
    "    description=\"A simple bot that echoes what you type\",\n",
    "    flagging_mode=\"never\"\n",
    ")\n",
    "\n",
    "# Launch the interface\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d036210",
   "metadata": {},
   "source": [
    "## 3. 构建基本聊天机器人\n",
    "\n",
    "让我们使用OpenAI创建一个简单的聊天机器人："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fb4cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get response from OpenAI. We already went through that before. \n",
    "def get_response(message):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": message}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# We will create the same exact gradio interface as before, but we will use get_response \n",
    "# function instead of echo! The get_response function will call the Open AI with the \n",
    "# message and return the response. The response will be displayed in the output box.\n",
    "# Basically, the user will enter a message in the input box, and when they click the \n",
    "# submit button, it will call the get_response function with the input text and display \n",
    "# the output in the output box.\n",
    "\n",
    "chatbot = gr.Interface(\n",
    "    fn=get_response,\n",
    "    inputs=gr.Textbox(placeholder=\"Ask me anything...\"),\n",
    "    outputs=\"text\",\n",
    "    title=\"Simple AI Chatbot\",\n",
    "    description=\"Chat with an AI assistant powered by OpenAI\",\n",
    "    flagging_mode=\"never\"\n",
    ")\n",
    "\n",
    "# Launch the chatbot\n",
    "chatbot.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e38af8",
   "metadata": {},
   "source": [
    "## 4. 创建流式聊天机器人"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba629b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to stream responses from OpenAI\n",
    "def stream_response(message):\n",
    "    stream = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": message}\n",
    "        ],\n",
    "        stream=True\n",
    "    )\n",
    "    \n",
    "    response = \"\"\n",
    "    for chunk in stream:\n",
    "        if chunk.choices[0].delta.content is not None:\n",
    "            response += chunk.choices[0].delta.content\n",
    "            # yield is a python keyword that allows you to return a value from a function \n",
    "            # without terminating the function. This means that the function can be called \n",
    "            # again later, and it will continue from where it left off. This is useful \n",
    "            # for streaming responses, as it allows you to return partial results as they \n",
    "            # are generated. So this is instead of return, which would terminate the function.\n",
    "            yield response \n",
    "\n",
    "# Create a streaming chatbot interface\n",
    "streaming_chatbot = gr.Interface(\n",
    "    fn=stream_response,\n",
    "    inputs=\"textbox\",\n",
    "    outputs=\"text\",\n",
    "    title=\"Streaming AI Chatbot\",\n",
    "    description=\"Chat with an AI assistant that streams responses in real-time\",\n",
    "    flagging_mode=\"never\"\n",
    ")\n",
    "\n",
    "# Launch the streaming chatbot\n",
    "streaming_chatbot.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709bb74a",
   "metadata": {},
   "source": [
    "## 5. 构建带记忆的聊天机器人\n",
    "\n",
    "现在让我们创建一个更高级的聊天机器人，它能记住对话历史。\n",
    "\n",
    "我们之前已经经历过这个过程，我们只是将其添加到Gradio界面中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea39a580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function called chat, which accepts the user message and conversation history\n",
    "def chat(message, history):\n",
    "    # Initialize messages with system prompt\n",
    "    messages = [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}]\n",
    "    \n",
    "    # We are looping through the history of messages (initially just an empty list). \n",
    "    # Entry is a single message in the history\n",
    "    for entry in history:\n",
    "        # Check if entry is in list format [user_msg, assistant_msg]\n",
    "        if isinstance(entry, list) and len(entry) == 2:\n",
    "            user_msg, assistant_msg = entry\n",
    "            # Add user message\n",
    "            messages.append({\"role\": \"user\", \"content\": user_msg})\n",
    "            # Add assistant message if it exists\n",
    "            if assistant_msg:\n",
    "                messages.append({\"role\": \"assistant\", \"content\": assistant_msg})\n",
    "        # If history is already in OpenAI format with role and content\n",
    "        elif isinstance(entry, dict) and \"role\" in entry and \"content\" in entry:\n",
    "            messages.append(entry)\n",
    "    \n",
    "    # Add the new user message to the conversation\n",
    "    messages.append({\"role\": \"user\", \"content\": message})\n",
    "    \n",
    "    # Get streaming response from OpenAI\n",
    "    stream = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=messages,\n",
    "        stream=True\n",
    "    )\n",
    "    \n",
    "    # Return the response chunk by chunk as it arrives\n",
    "    response = \"\"\n",
    "    for chunk in stream:\n",
    "        if chunk.choices[0].delta.content is not None:\n",
    "            response += chunk.choices[0].delta.content\n",
    "            yield response\n",
    "\n",
    "# Create and launch the chatbot interface\n",
    "memory_chatbot = gr.ChatInterface(\n",
    "    fn=chat,\n",
    "    title=\"AI Chatbot with Memory\",\n",
    "    description=\"Chat with an AI assistant that remembers your conversation history.\",\n",
    "    examples=[\"Tell me about machine learning\", \"How do neural networks work?\"],\n",
    "    flagging_mode=\"never\"\n",
    ")\n",
    "\n",
    "memory_chatbot.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c47459",
   "metadata": {},
   "source": [
    "## 6. 餐厅菜单生成器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aae052d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate a restaurant menu\n",
    "def generate_menu(restaurant_name, cuisine_type, special_requirements=\"None\"):\n",
    "    prompt = f\"\"\"\n",
    "    Create a restaurant menu for \"{restaurant_name}\", a {cuisine_type} restaurant.\n",
    "    Special requirements: {special_requirements}\n",
    "    \n",
    "    Include:\n",
    "    - 3 appetizers\n",
    "    - 4 main courses\n",
    "    - 2 desserts\n",
    "    \n",
    "    For each item, include a name, brief description, and price.\n",
    "    \n",
    "    Format your response in markdown with appropriate headers, styling, and sections.\n",
    "    Add a brief introduction about the restaurant at the top.\n",
    "    \"\"\"\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert restaurant consultant who creates beautiful, well-formatted menus.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Create a menu generator interface\n",
    "menu_generator = gr.Interface(\n",
    "    fn=generate_menu,\n",
    "    inputs=[\n",
    "        gr.Textbox(label=\"Restaurant Name\"),\n",
    "        gr.Textbox(label=\"Cuisine Type (e.g., Italian, Japanese)\"),\n",
    "        gr.Textbox(label=\"Special Requirements (Optional)\", placeholder=\"e.g., vegetarian options\")\n",
    "    ],\n",
    "    outputs=gr.Markdown(label=\"Generated Menu\"),\n",
    "    title=\"Restaurant Menu Generator\",\n",
    "    description=\"Create a professional restaurant menu with AI\",\n",
    "    flagging_mode=\"never\"\n",
    ")\n",
    "\n",
    "# Launch the menu generator\n",
    "menu_generator.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17de182c",
   "metadata": {},
   "source": [
    "## 7. 进一步学习资源\n",
    "\n",
    "- [Gradio文档](https://www.gradio.app/docs/)\n",
    "- [OpenAI API文档](https://platform.openai.com/docs/api-reference)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
